# High-Energy-Physics
One of the ways to develop theories nowadays is to develop an experimental device that probes the universe. The collected information might give hints to theoreticians about the better version of a current model. For example, how to include newly absorbed phenomena into it and improve the accuracy of model predictions for further experiments. CERN is a French abbreviation for Center of European Nuclear Research. Essentially, it is a vast laboratory. There are several distinct experiments that take place. And everyone is operated by an international collaboration that unites physicists or scientists from different countries. People from 100 different countries work together despite political difficulties and misunderstanding on governmental levels.
They focused their intellectual efforts on the development of better understanding of our universe on the development of new technologies. So it is a fascinating place. And there are, of course, some by-products that you're most likely aware of. For example, CERN is the birth place of the World Wide Web. So you are using this to watch this lecture. Also, one of the great things built there is called Large Hadron Collider. It has been used for discovery of Higgs boson, and it is one of the finest and the biggest data generation machine ever created.


By design, it is a machine for smashing protons and examining outcomes. By effect, it is a massive arena for examining different models striving for better explanation of the universe. Let us take a closer look at LHC. It is a 27 km-long tunnel, 50 to 175 meters deep, and the protons are accelerated to the speed almost comparable to the speed of light. And the energy collision on those protons is up to 14 teraelectronvolts. There are four big detectors located around the ring. Those are called ALICE, ATLAS, CMS and LHCb. So there are 40 million bunches of proton that collide every second. Every detector generates enormous amounts of data, for example, since the beginning, hundred of petabytes has been stored for later data analysis. Let's take a look at the cycle that starts from the very beginning till the discovery or publication has been created. So we start with creation of protons out of hydrogen atoms, and then we accelerate those to the speed almost equal to the speed of light. Then those protons are grouped into bunches. And those bunches are smashed into each other. And during this collision, set of particles appear out of the energy of this collision, and those are called events.


Then the detector that sits around place of this collision records information of the energy that is deposited by every particle flying out of the event. And can convert this information of the energy into the hits that you can record and store.
Left after after this, the algorithm that tries to reconstruct trajectories of different particles, and identify types of those particles comes to action.
After we get the picture of individual trajectories, we combine them into vertices and form a structural of the whole event. Then we build the map of the event and filter for the further analysis only those that have some meaning from the physical point of view.
And only after this, we analyze statistical properties of those events that has been stored and make conclusion about validity of models that predict existence of certain events of certain part of the events.


So at the place of collision there is a detector which is essentially a sub-atomic digital camera. Sits and in records outcome of the collision that happens during the data taking. On the upper part of this image, you see the mechanical design of LHCb detector. And at the bottom part of this image, you will see reconstructed trajectories of elementary particles that have been detected by this detector.
Their collection of lines that has been reconstructed for the whole event. And the data is used for this analysis, for this reconstruction, come from various parts of the directories, not only the backside or downstream side. It also comes from, there is a middle part that is called tracker. And there is a very precise part of the detector that sits around the place of the collision. It is called vertex locator. That gives most of the information about the particle trajectory. And then we have to identify what kind of particle every track represents.


We can use various sources of information. The first one is that every particle leaves different traces in different subdetectors of the experiment. For example, Electrons leave tracks at tracking system and electromagnetic calorimeter. Photons leave no traces in tracking system but leave traces electromagnetic calorimeter. Hard ones such as protons, Kaons, and pions, leave tracks in inner most tracking system and electromagnetic calorimeter and hadronic calorimeter. And there is a special kind of particles that are called muons, they're heavier brothers of electrons that fly through the whole detector and leave traces everywhere.
So collection of the information that those sub-detectors provide allows us to deduce the type of the particle. And this actually is one of the machine learning problems that is being solved at every experiment. After you got the picture of individual tracks, it is important to reconstruct the whole image, the whole event that consists of tracks and vertices that happen during the particle decays. There are so-called secondary vertices that correspond to a very short flight of a particle that is then decayed into something else. After this trajectory's particle identification and vertex identification has been happened, we still have to understand whether or not inside this event, something interesting has actually happened. And for this purpose, we have special selection procedures that are called triggers. There are two stages of triggers. The first one is hardware trigger that reduces the rate of the event from 40 MHz to 1 MHz. And there is a software trigger that reduces this rate even further, and output of this trigger is being use for offline analysis and eventually for discovery.
Design of the triggers is actually a quite interesting problem from machine learning perspective. My group has been taking part and design of the triggers for LHCb experiment, and it works in data taking since 2015. 


So precise and fast particle tracking, single tracks, showers and jets kind of objects that detector operate with. Particle identification, how can you discriminate between different kinds of particles? Fast and accurate online data processing and filtering. How you make sure that data collected can be trusted. If there is anomaly happening during the data taking, you should disregard the model data taken during the period.
You should take certain measures to fix the infrastructure to improve quality of the data. And, of course, there are very interesting topic of design optimization of the detector, where various techniques like Bayesian optimization and surrogate modelling can be used. And here's example of a tracking problem that we'll cover during the next lecture. Given the set of hits represented by points here, you should be able to reconstruct the tracks and estimate parameters of those tracks as precisely as possible.

#LHC
The ALICE (A Large Ion Collider Experiment) experiment is a particle physics experiment designed to study the behavior of matter under extreme temperature and density conditions, such as those thought to have existed in the early universe. ALICE is located at the Large Hadron Collider (LHC) at CERN (the European Organization for Nuclear Research) in Switzerland, and it is one of several experiments at the LHC that are designed to study the fundamental nature of matter and the forces that shape the universe.
ALICE uses proton-proton collisions to study the properties of quarks and gluons, the building blocks of protons, and to search for new, undiscovered particles. The experiment is specifically designed to study the behavior of strongly interacting matter, known as quark-gluon plasma (QGP), which is thought to have existed in the first few microseconds after the Big Bang.
By colliding protons at high energies, ALICE creates conditions of extreme temperature and density that allow scientists to study the properties of QGP and how it behaves under different conditions. Through these studies, ALICE aims to shed light on the fundamental nature of matter and the forces that shape the universe.
 
# Quark Gluon Plasma
Quark-gluon plasma (QGP) is a state of matter that is believed to have existed in the early universe just a few microseconds after the Big Bang. It is a form of matter in which quarks and gluons, the building blocks of protons and neutrons, are no longer confined within these particles and can move freely.
The existence of quark-gluon plasma was first proposed in the 1970s, and it was in the 2000s that scientists were able to create and study this state of matter in the laboratory. This is done by colliding heavy ions, such as gold or lead, at extremely high energies using particle accelerators. When the ions collide, the energy of the collision is so high that it can create a new state of matter in which the quarks and gluons are no longer bound within protons and neutrons.
Quark-gluon plasma is a very hot and dense state of matter, with temperatures reaching up to several trillion degrees Celsius. It is thought to be the most fundamental state of matter, and understanding it can help us better understand the early universe and the fundamental nature of matter.
Quark-gluon plasma is believed to be the state of matter that existed in the early universe just a few microseconds after the Big Bang. By recreating and studying this state of matter in the laboratory, scientists can gain insight into the properties and behavior of matter at extremely high temperatures and densities, which can help us better understand the conditions that existed in the early universe.
For example, quark-gluon plasma is thought to be a "perfect fluid," meaning it has extremely low viscosity and can flow very easily. This is because the quarks and gluons in the plasma are able to move freely and interact with each other. Understanding the properties of quark-gluon plasma can help us understand how the early universe expanded and cooled and how it eventually led to the formation of the first stable atoms.
In addition, the study of quark-gluon plasma can also help us better understand the fundamental nature of matter itself. Quarks and gluons are the building blocks of protons and neutrons, and understanding how they behave in the plasma can give us insight into the fundamental forces that govern the behavior of matter at the most basic level.
 
# QCD Phase Diagram
The QCD phase diagram is a map that shows the different states of matter that can exist under different conditions of temperature and density. QCD stands for quantum chromodynamics, which is the theory that describes the strong nuclear force that holds quarks together within protons and neutrons.
The QCD phase diagram is divided into four main regions: hadronic matter, quark-gluon plasma, color-superconducting quark matter, and color-flavor-locked quark matter.
The hadronic matter is the state of matter that we are most familiar with, and it is made up of protons and neutrons. The hadronic case becomes a quark-gluon plasma at high temperatures and low densities. The quarks and gluons that makeup protons and neutrons are no longer confined within these particles and can move freely.
At very high densities and low temperatures, quark matter can become a color-superconductor, in which the quarks form Cooper pairs, and the case exhibits superconducting behavior. At even higher densities and lower temperatures, quark matter can become a color-flavor-locked state, in which the quarks are strongly interacting, and the matter behaves like a superfluid.
The QCD phase diagram is an essential tool for understanding the behavior of matter under different conditions and for predicting the properties of matter in extreme environments, such as the cores of neutron stars or the early universe.
 
 
 
# STAR Detector
The Solenoidal Tracker At RHIC (STAR) is a particle detector located at the Relativistic Heavy Ion Collider (RHIC) at the Brookhaven National Laboratory in Upton, New York. It is designed to study the properties of the strong force, which is one of the four fundamental forces of nature, by colliding with heavy ions (such as gold or lead) at high energies.
The STAR detector consists of several different subdetectors, each of which is designed to measure different properties of the particles produced in the collisions. The central part of the detector is a solenoidal magnet, which generates a strong magnetic field that bends the paths of charged particles as they pass through it. This allows the detector to measure the momentum of the particles and reconstruct their trajectories.
A time projection chamber (TPC) measures the ionization (energy loss) of charged particles as they pass through it, allowing the detector to identify different types of particles and measure their energies.
A barrel electromagnetic calorimeter (BEMC) measures the energy of photons (particles of light) produced in collisions.
A forward time projection chamber (FTPC) is located near the ends of the detector and is used to measure the properties of particles produced at large angles with respect to the beam axis.
The STAR detector is used to study a variety of phenomena in high-energy nuclear physics, including the Quark-Gluon Plasma (QGP), a state of matter believed to have existed in the early universe. By colliding heavy ions at high energies, researchers can create conditions similar to those that existed in the first few microseconds of the universe, allowing them to study the properties of the QGP and gain insights into the fundamental nature of matter.
 
 
#Multiplicity Density
The charged-particle multiplicity density at midrapidity in Pb-Pb collisions is a measure of the number of charged particles produced in the collision per unit of rapidity (a measure of the particle's velocity relative to the speed of light) around the center of the rapidity distribution. The centrality of the collision refers to the degree to which the two colliding nuclei overlap. In general, the charged-particle multiplicity density increases with increasing centrality, meaning that more charged particles are produced in more central collisions.
One way to study the charged-particle multiplicity density at midrapidity in Pb-Pb collisions is through heavy ion collisions at the Large Hadron Collider (LHC). At the LHC, researchers can measure the charged-particle multiplicity density at midrapidity in different centrality classes by analyzing the particles produced in the collision. This can provide insight into the properties of quark-gluon plasma (QGP), a state of matter thought to have existed in the early universe, which is thought to be produced in these collisions.
Understanding the centrality dependence of the charged-particle multiplicity density at midrapidity in Pb-Pb collisions can also help researchers better understand the dynamics of the collision itself and the mechanisms driving particle production in these collisions.
 
 
 
 
#Central Collision
In a central collision, the two colliding nuclei overlap completely, resulting in a high degree of overlap between the constituent protons and neutrons. This leads to a large number of collisions between the individual nucleons, leading to the production of many particles in the collision.
Central collisions are typically characterized by a high charged-particle multiplicity density at midrapidity, as a large number of collisions leads to the production of many charged particles. These collisions can also lead to the production of high-energy particles, such as jets, which are energetic sprays of particles produced when quarks and gluons within the colliding nuclei interact.
Central collisions are of particular interest to researchers studying the quark-gluon plasma (QGP), a state of matter thought to have existed in the early universe and which is thought to be produced in these types of collisions. The high energy densities and temperatures reached in central collisions can lead to the production of the QGP, making these collisions an ideal laboratory for studying this state of matter.
 
#Rapidity
Rapidity is a measure of the velocity of a particle relative to the speed of light. It is defined as the rapidity y of a particle with energy E and momentum p as follows:
y = 0.5 * ln((E + p) / (E - p))
Rapidity is related to the particle's momentum and energy through the equation of motion: E^2 = p^2 + m^2, where m is the particle's mass.
Rapidity is often used to describe the kinematics of high-energy particle collisions, as it allows researchers to study the properties of particles over a wide range of energies without considering the details of the particles' motion. For example, in heavy ion collisions, the rapidity distribution of the particles produced in the collision can provide insight into the properties of the quark-gluon plasma (QGP), a state of matter thought to have existed in the early universe, which is thought to be produced in these collisions.
In general, the rapidity of a particle is related to its velocity, with particles moving at higher velocities having larger rapidities. However, because the rapidity depends on the ratio of the particle's energy to its momentum, it is not simply a measure of velocity, but also considers the particle's mass. This means that two particles with the same velocity but different masses can have different rapidities.
 
The charged-particle multiplicity density at midrapidity in Pb-Pb collisions is a measure of the number of charged particles produced in the collision per unit of rapidity (a measure of the particle's velocity relative to the speed of light) around the center of the rapidity distribution. The centrality of the collision refers to the degree to which the two colliding nuclei overlap. In general, the charged-particle multiplicity density increases with increasing centrality, meaning that more charged particles are produced in more central collisions.
One way to study the charged-particle multiplicity density at midrapidity in Pb-Pb collisions is through heavy ion collisions at the Large Hadron Collider (LHC). At the LHC, researchers can measure the charged-particle multiplicity density at midrapidity in different centrality classes by analyzing the particles produced in the collision. This can provide insight into the properties of the quark-gluon plasma (QGP), a state of matter thought to have existed in the early universe, which is thought to be produced in these collisions.
Understanding the centrality dependence of the charged-particle multiplicity density at midrapidity in Pb-Pb collisions can also help researchers better understand the dynamics of the collision itself and the mechanisms driving particle production in these collisions.

